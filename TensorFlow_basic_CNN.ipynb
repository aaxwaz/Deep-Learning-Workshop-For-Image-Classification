{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUS Deep Learning workshop on computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is TensorFlow\n",
    "* A system for executing computational graphs over Tensor objects - n-dimensional arrays analogous to the numpy ndarray.\n",
    "* Native support for performing backpropogation for its Variables. \n",
    "* Used by Google for both research and production. \n",
    "\n",
    "### Why use Tensorflow\n",
    "\n",
    "* Save you a lot of time when buiding large computational graphs - can automatically compute gradients to update weights!\n",
    "* Code can be run on GPU - usually 5x - 20x times faster than CPU for usually image networks. And you don't need to worry about low level cuda-code, things are taken care for you in tf. \n",
    "* A lot of good high level APIs or pre-trained models that you can use directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief example of tensorflow  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph building blocks: \n",
    "1) Placeholder: input nodes to our graph, which serve as entry points where we can feed data into graph - `tf.placeholder`\n",
    "\n",
    "2) Variables: tensors that hold values in the graph, which will be updated during training - `tf.Variable`\n",
    "\n",
    "3) Ops: arithmetic operators, as well as activation, convolution, loss ops and many more - \n",
    "* a = tf.constant([3, 6])\n",
    "* b = tf.constant([2, 2])\n",
    "* tf.add(a, b) # >> [5 8]\n",
    "* tf.add_n([a, b, b]) # >> [7 10]. Equivalent to a + b + b\n",
    "* tf.mul(a, b) # >> [6 12] because mul is element wise\n",
    "* tf.matmul(a, b) # >> ValueError\n",
    "* tf.matmul(tf.reshape(a, shape=[1, 2]), tf.reshape(b, shape=[2, 1])) # >> [[18]]\n",
    "* tf.div(a, b) # >> [1 3]\n",
    "* tf.mod(a, b) # >> [1 0]\n",
    "\n",
    "* tf.nn*, such as tf.nn.conv2d, tf.nn.max_pool, tf.nn.softmax, tf.nn.relu, and so on\n",
    "\n",
    "4) tf.train* subclasses: Optimizer base classes that compute gradients for a loss and apply gradients to variables. Such as tf.train.GradientDescentOptimizer, tf.train.AdadeltaOptimizer, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Build the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x121d03630>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADGCAYAAADc30sqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpwEeiGEiHAS6IUQIsL9P0ttCpDSc3GfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121b10b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "img = plt.imread('./images/LM.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "N = 128 # sample size \n",
    "D = 5 # data dimension \n",
    "H = 2 # hidden layer dimension \n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(N, D), name = 'input')\n",
    "y = tf.placeholder(tf.float32, shape=(N, 1), name = 'target')\n",
    "\n",
    "# all weights for model \n",
    "w1 = tf.Variable(tf.random_normal((D, H)), name = 'weights1')\n",
    "b1 = tf.Variable(tf.zeros([2]), name = 'biases1')\n",
    "w2 = tf.Variable(tf.random_normal((H, 1)), name = 'weights2')\n",
    "b2 = tf.Variable(tf.zeros([1]), name = 'biases1')\n",
    "\n",
    "# relu hidden layer\n",
    "h = tf.maximum(tf.matmul(x, w1) + b1, 0)\n",
    "\n",
    "# output layer \n",
    "y_pred = tf.matmul(h, w2) + b2\n",
    "\n",
    "# loss \n",
    "loss = tf.reduce_mean((y_pred - y)**2)\n",
    "\n",
    "# update \n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-3)\n",
    "updates = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'weights1:0' shape=(5, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'biases1:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'weights2:0' shape=(2, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'biases1_1:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x = np.random.randn(N, D)\n",
    "data_y = np.random.randn(N, 1)\n",
    "\n",
    "data = {x: data_x, \n",
    "        y: data_y}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    losses = []\n",
    "    for t in range(1000):\n",
    "        loss_val, _  = sess.run([loss, updates], \n",
    "                                feed_dict = data)\n",
    "        losses.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x121191cc0>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121250d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Can switch to high-level layers too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(N, D), name = 'input')\n",
    "y = tf.placeholder(tf.float32, shape=(N, 1), name = 'target')\n",
    "\n",
    "# weights initializer\n",
    "init = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "# hidden layer\n",
    "h = tf.layers.dense(inputs=x, units=H, \n",
    "                    activation=tf.nn.relu, \n",
    "                    kernel_initializer = init, \n",
    "                    name='hidden_layer')\n",
    "\n",
    "# output layer\n",
    "y_pred = tf.layers.dense(inputs=h, units=1, \n",
    "                        kernel_initializer = init, \n",
    "                        name='output_layer')\n",
    "\n",
    "# loss\n",
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "# updates\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-3)\n",
    "updates = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {x: data_x, \n",
    "        y: data_y}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    losses = []\n",
    "    for t in range(1000):\n",
    "        loss_val, _  = sess.run([loss, updates], \n",
    "                                feed_dict = data)\n",
    "        losses.append(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12140fb38>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHrpJREFUeJzt3Xl4XPV97/H3dzaN1tEuW5aFbMsG\nL9gxVmyCDYGwtyzJE7K4NDSBlCaF23RJmuW2TfK0vbltcxMSkpSQlBDShLQsgQBhKyEYCJu8b3gB\nb7JsS5asfZd+948ZG9vYlmyNdDRnPq/nmWdmzvlJ53t07M+c+Z3fOcecc4iIiL8EvC5ARESST+Eu\nIuJDCncRER9SuIuI+JDCXUTEhxTuIiI+pHAXEfEhhbuIiA8p3EVEfCjk1YKLi4tdVVWVV4sXEUlJ\nK1euPOicKxmunWfhXlVVRW1trVeLFxFJSWa2ayTt1C0jIuJDCncRER9SuIuI+JDCXUTEhxTuIiI+\npHAXEfEhhbuIiA+lXLhv2d/O//nNZjp7B7wuRURkwkq5cK871MXdK95m0742r0sREZmwUi7cz50S\nA2BdXavHlYiITFwpF+6leVEm5UVZX9fidSkiIhNWyoU7wLkVMdbt1Z67iMjJpGS4z58S4+3GTtp7\n+r0uRURkQkrJcD+3It7vvmGvDqqKiJxIaoZ74qDq+r3qdxcROZGUDPeinAym5GdqxIyIyEmkZLgD\nzK+IsV4HVUVETihlw/3cihi7mrpo7dJBVRGR46VsuM+fkg+gvXcRkRNI2XB/56Cqwl1E5HgpG+6x\nrDCVhVkaMSMicgIpG+4Q73dfu0d77iIix0vpcF84NZ+9Ld00tPd4XYqIyISS2uFeWQDAql3qmhER\nOVpKh/u8KXlEggFW7z7kdSkiIhNKSod7RijI3Cl5rFK4i4gcI6XDHeC8ygLW1bXSNzDkdSkiIhOG\nL8K9d2CIzbrtnojIESkf7gsr42eqqmtGROQdKR/u5fmZTMqLsmq3RsyIiBw2bLib2T1m1mBmG07R\n5mIzW2NmG83sheSWOLzzzspn1S7tuYuIHDaSPfd7gatONtPM8oEfANc55+YCH0lOaSN3XmVB/GSm\nNp3MJCICIwh359wKoPkUTf4IeNg5tzvRviFJtY3YkZOZ1DUjIgIkp899FlBgZr8zs5VmdtPJGprZ\nrWZWa2a1jY2NSVh0nE5mEhE5VjLCPQQsAv4QuBL4ezObdaKGzrm7nXM1zrmakpKSJCw6LiMU5NyK\nGG/sPNUXDBGR9JGMcK8DnnLOdTrnDgIrgAVJ+L2nZfG0QtbVtdLdNzjeixYRmXCSEe6PAheaWcjM\nsoAlwOYk/N7TsnhaIQNDTuPdRUSId6mckpndD1wMFJtZHfBVIAzgnLvLObfZzJ4C1gFDwI+dcycd\nNjlWas4qIGDw2o5mllYXj/fiRUQmlGHD3Tm3fARt/g34t6RUdIZyo2Hmlsd4fUeTl2WIiEwIKX+G\n6tEWTytk9e4WegfU7y4i6c134d47MMT6Ot16T0TSm6/C/b1VhUC8311EJJ35KtwLsyOcXZarcBeR\ntOercId418zKnc0MDOrmHSKSvnwZ7p19g2zSzTtEJI35LtyXTIv3u7/yloZEikj68l24l+ZFmVma\nw8sKdxFJY74Ld4Cl1cW8vqNJ491FJG35Ntx7+odYtUvXdxeR9OTLcF8yvZBgwHh5+0GvSxER8YQv\nwz0vGmZBRYyX31K4i0h68mW4AyyrLmbtnhbaevq9LkVEZNz5NtyXVhcz5OBVjZoRkTTk23BfWFlA\nZjiofncRSUu+DfdIKMDiaYUa7y4iacm34Q7xfvftDR3sa+32uhQRkXHl63C/aFYJAC9safS4EhGR\n8eXrcJ9VlkN5LMrzWxq8LkVEZFz5OtzNjIvPKeWlbQfpG9AlgEUkffg63AEunlVCZ98gtbt0Aw8R\nSR++D/el1cWEg8bv1O8uImnE9+GenRFiybQinn9T/e4ikj58H+4AF59dwraGDuoOdXldiojIuEiT\ncC8FUNeMiKSNtAj3GSXZTC3M5HcaEikiaSItwt3M+MDZpby0/SDdfbo7k4j4X1qEO8DlcybR0z/E\ni9vUNSMi/jdsuJvZPWbWYGYbTjL/YjNrNbM1icc/JL/M0VsyvZC8aIhnNh3wuhQRkTEXGkGbe4Hv\nAfedos2LzrlrklLRGAkHA1w6u4znNh9gYHCIUDBtvrSISBoaNuGccysAX5zeecWcMg519fPGzkNe\nlyIiMqaStfv6PjNba2ZPmtncJP3OpLtoVgmRUIBnNu33uhQRkTGVjHBfBZzlnFsA3Ak8crKGZnar\nmdWaWW1j4/gf2MzOCHHRzGKe2XgA59y4L19EZLyMOtydc23OuY7E698AYTMrPknbu51zNc65mpKS\nktEu+oxcMWcSe1u62bSvzZPli4iMh1GHu5lNMjNLvF6c+J0T9t52l84uJWDw9EaNmhER/xrJUMj7\ngVeAs82szsxuMbPPmNlnEk1uADaY2Vrgu8DH3QTu8yjKyeC9VYU8sa5eXTMi4lvDDoV0zi0fZv73\niA+VTBnXLCjn7x/ZwJv725k9Oc/rckREki4tB3tfPW8SwYDx+Lp6r0sRERkTaRnuxTkZXDCjiMfX\n7VPXjIj4UlqGO8A18yezq6mLDXs1akZE/Cdtw/3KuZMIBYzH1DUjIj6UtuGenxXholklPKGuGRHx\nobQNd4h3zext6WbVbl1rRkT8Ja3D/fI5ZUTDAX61eq/XpYiIJFVah3tuNMyVcyfx2Np99A7oDk0i\n4h9pHe4AHz6vgtbufp7brPurioh/pH24L60uZlJelIdW1nldiohI0qR9uAcDxgcXTuF3WxtpbO/1\nuhwRkaRI+3AHuGHRFAaHHI+u0YFVEfEHhTtQXZrLgooYD61SuIuIPyjcEz68qILN+9pYX9fqdSki\nIqOmcE+4/j1TiIYD/OL1XV6XIiIyagr3hFhmmGvnl/Pomnrae/q9LkdEZFQU7ke58fyz6Oob5JE1\nupiYiKQ2hftRFlTEmDM5j1+8tlsXExORlKZwP4qZceP5lWze18bqPS1elyMicsYU7se5/j1TyI4E\n+fmru70uRUTkjCncj5OTEeL6hVN4fF09LV19XpcjInJGFO4n8Inzz6J3YIj7X9/jdSkiImdE4X4C\nsyfnccGMIn76+530Dw55XY6IyGlTuJ/ELcumsb+th9+s3+d1KSIip03hfhKXnF3KtOJs7nlph4ZF\nikjKUbifRCBgfGppFWvrWnWPVRFJOQr3U/jweRXkRUP8x0s7vC5FROS0KNxPITsjxPIllTy1YT97\nmru8LkdEZMQU7sP41AXTCAaMu154y+tSRERGbNhwN7N7zKzBzDYM0+69ZjZoZjckrzzvTYpFuWHR\nVB6oreNAW4/X5YiIjMhI9tzvBa46VQMzCwL/AjydhJomnM++fwaDzvGjFW97XYqIyIgMG+7OuRVA\n8zDN/hfwENCQjKImmsqiLK5bUM7PX9tNc6cuSSAiE9+o+9zNbArwIeCuEbS91cxqzay2sbFxtIse\nV39+8Qy6+wf5ycsaOSMiE18yDqjeAXzROTc4XEPn3N3OuRrnXE1JSUkSFj1+ZpblctXcSdz7+520\n6U5NIjLBJSPca4BfmtlO4AbgB2b2wST83gnn9g9U094zwD0a9y4iE9yow905N805V+WcqwIeBP7c\nOffIqCubgOZNiXH1vEn8+MUd6nsXkQltJEMh7wdeAc42szozu8XMPmNmnxn78iaev758Fl19Axr3\nLiITWmi4Bs655SP9Zc65T46qmhQwsyyXDy2s4Ke/38nNS6cxKRb1uiQRkXfRGapn4C8vm8mQc9z5\n221elyIickIK9zMwtTCL5Ysr+a839rCrqdPrckRE3kXhfoZuv6SaSCjA/33yTa9LERF5F4X7GSrN\ni/LZ98/gyQ37efXtJq/LERE5hsJ9FP70oumUx6L80xObGBrS3ZpEZOJQuI9CNBzki1efw4a9bTy0\nqs7rckREjlC4j9J1C8p5z9R8/vXpLXT2DnhdjogIoHAfNTPj76+ZQ2N7L9/V0EgRmSAU7kmw6KwC\nPlpTwX+8uIMt+9u9LkdEROGeLF+6ejY50RB/98h6HVwVEc8p3JOkMDvCl68+hzd2HuJBHVwVEY8p\n3JPoI4umUnNWAd/4zWYO6aqRIuIhhXsSBQLGP31oHu09A3z9sY1elyMiaUzhnmTnTMrjtkuqeWRN\nPc9s3O91OSKSphTuY+C2S6qZPTmPr/xqg7pnRMQTCvcxEAkF+OZH5tPS1cfX1D0jIh5QuI+RueUx\nbv9ANY+uqeepDeqeEZHxpXAfQ7ddUs3c8jy+8qv1HGjr8bocEUkjCvcxFA4G+M7HF9LdN8hf/dca\nBnVyk4iME4X7GKsuzeFr183h92816abaIjJuFO7j4KM1U7lm/mS+9exWVu0+5HU5IpIGFO7jwMz4\n5w+dy+RYlL+4fzUtXRoeKSJjS+E+TmKZYe5cvpADbT187pfqfxeRsaVwH0cLKwv42nVzeWFrI99+\ndqvX5YiIjyncx9kfLa7kYzVT+d7z23lalycQkTGicB9nZsbXr5/LgooYf/Pfa9ne0OF1SSLiQwp3\nD0TDQf79jxeREQrwp/fV6vozIpJ0CnePlOdncvdNi9jb0s2tP6ulp3/Q65JExEeGDXczu8fMGsxs\nw0nmX29m68xsjZnVmtmy5JfpT4vOKuRbH13AGzsP8YUH1+n2fCKSNCPZc78XuOoU858DFjjn3gPc\nDPw4CXWljWvml/O3V53NY2vr+eYzW7wuR0R8IjRcA+fcCjOrOsX8o48IZgPa/TxNn33/DPY0d/GD\n371FSW4Gn1o6zeuSRCTFDRvuI2FmHwK+AZQCf5iM35lOzIx/vH4ezZ19fP2xTeRkhPhIzVSvyxKR\nFJaUA6rOuV85584BPgj848namdmtiX752sbGxmQs2jdCwQDfXb6QC2cW88WH1vHk+n1elyQiKSyp\no2WccyuAGWZWfJL5dzvnapxzNSUlJclctC9khIL88BOLWFhZwF/8cjUvbNUHoIicmVGHu5lVm5kl\nXp8HRICm0f7edJUVCXHPJ9/LzNJc/vS+Wp7f0uB1SSKSgkYyFPJ+4BXgbDOrM7NbzOwzZvaZRJMP\nAxvMbA3wfeBjzjkdVB2FWGaYn396CTNLc/iz+1by7KYDXpckIinGvMrhmpoaV1tb68myU0VrVz83\n/eR1Nu5t5c7lC7n63MlelyQiHjOzlc65muHa6QzVCSyWFeY/b1nMgqn53H7/ah5aWed1SSKSIhTu\nE1xuNMx9Ny/m/OmF/M0Da/nB77ajXi8RGY7CPQVkZ4T4yScXc92Ccv71qS189dcbdbMPETmlpJzE\nJGMvEgpwx8few6RYlLtXvM2Bth6+8/GFRMNBr0sTkQlIe+4pJBAwvvIHs/mHa+bwzKYDfOSuV9jX\n2u11WSIyASncU9DNy6Zx9ydq2HGwk2vvfJnanc1elyQiE4zCPUVdPqeMX/35BeRkBFn+o1f55eu7\nvS5JRCYQhXsKm1mWy6O3LeP86UV86eH1fPHBdXT36aYfIqJwT3mxrDA/+eR7ue2SGfz3yj188Psv\ns72h3euyRMRjCncfCAUDfOHKc/jppxZzsKOXa+98mQd1wpNIWlO4+8hFs0r4zecuZMHUGJ9/YC23\n/2KVbr4tkqYU7j5Tlhfl558+ny9ceTZPb9zP5d9ewf/owmMiaUfh7kPBgHHbJdU8etsyinMifPq+\nWj7/wFraevq9Lk1ExonC3cfmlOfx69uXcfsl1Ty8qo7L/t8LPLFun65NI5IGFO4+FwkF+PyVZ/PI\nbUspyc3gtl+s4uZ732BPc5fXpYnIGFK4p4n5Ffk8ettS/u4PZ/Pajmau+PYKfvjCW/QPDnldmoiM\nAYV7GgkFA3z6wuk8+9fvZ2l1Ed948k2uvfMlXnlLd0UU8RuFexqakp/Jj26q4a4/XkRbdz/Lf/Qq\nt9z7BtsO6OQnEb9QuKcpM+OqeZP47ecv5otXncPrO5q58o4VfPnhdTS09XhdnoiMku6hKgA0d/Zx\n52+38Z+v7iIUCHDTBWfxZxfNoDA74nVpInKUkd5DVeEux9jV1Mm3nt3Kr9fWkxUOcvOyaXx62XRi\nWWGvSxMRFO4yStsOtHPHc9t4Yt0+cqMhblk2jU9eUEV+lvbkRbykcJek2Lyvje/8zzae2rifrEiQ\nj713Krcsm0ZFQZbXpYmkJYW7JNWW/e3cveJtHl2zFwdcO38yt140gznleV6XJpJWFO4yJupburnn\npR3c//puOvsGOX96ITe9r4rL55QRDmrwlchYU7jLmGrt6uf+N3bzs1d2sbelm7K8DG5cchYfXzyV\n0tyo1+WJ+JbCXcbF4JDj+TcbuO/VXazY2kg4aFw1bzJ/vKSSxdMKMTOvSxTxlZGGe2g8ihH/CgaM\ny+aUcdmcMt5u7OA/X93NAyv38NjaeqqKsrhhUQUfXlTB5Fim16WKpBXtuUvSdfUN8OT6/Tywcg+v\nvt1MwGDZzBI+WlPBZbPLiIaDXpcokrKS1i1jZvcA1wANzrl5J5h/I/DFxNsO4LPOubXDLVjhnh52\nNXXy0Mo6HlxZR31rDzkZIa6YU8a1C8pZNrNYB2FFTlMyw/0i4qF930nC/QJgs3PukJldDXzNObdk\nuAUr3NPL4JDjlbea+PXavTy1YT9tPQPkZ4W5et4krp1fzpLpRQQD6p8XGU5SD6iaWRXw+InC/bh2\nBcAG59yU4X6nwj199Q0M8eK2Rh5bW88zmw7Q1TdIUXaES2eXcvmcSSyrLiYzoq4bkRPx6oDqLcCT\nJ5tpZrcCtwJUVlYmedGSKiKhAJfOLuPS2WV09w3y/JYGntqwnyc37Oe/a+uIhgMsqy7hijllfGB2\nKcU5GV6XLJJykrbnbmaXAD8Aljnnhr37g/bc5Xh9A0O8vqOZZzft59lNB6hv7cEMFlUW8P5ZJVw4\nq4Rzp8TUfSNpbVy7ZcxsPvAr4Grn3NaRFKhwl1NxzrGxvo1nNx3guTcPsGFvGwD5WWGWVhfz/pkl\nXDirWEMsJe2MW7eMmVUCDwOfGGmwiwzHzJg3Jca8KTH+6vJZNHX08tL2g6zYepAXtzXyxLp9AMws\nzeGCGUUsmV7E4mmF6sIRSRjJaJn7gYuBYuAA8FUgDOCcu8vMfgx8GNiV+JGBkXyqaM9dzpRzji0H\n2nlx60FWbGukduchuvsHAaguzWHxtEKWTCvk/OlFlOXpUgjiL7r8gKSN/sEh1u9t5bW3m3ltRxO1\nOw/R0TsAQFVRFuedVcDCygIWTs3nnEm5hDS2XlKYwl3S1sDgEJv3tfPajiZe29HM6t2HONjRB0Bm\nOMi5FTEWTs1nYWU+CysLtHcvKUXhLpLgnKPuUDer97SwevchVu9uYVN9G32DQwBMyosyb0oec8pj\nzCvPY+6UGOWxqC56JhOSLhwmkmBmTC3MYmphFtctKAegd2CQTfVtrN7dwrq6FjbWt/HbNxsYSuzr\nFGSFmVseY24i7OeW51FVlK1hmJIyFO6SljJCwXg/fGXBkWndfYNs3t/Gxr2tbKxvY0N9Kz95eeeR\nPfyMUIAZJTnMKsthZlkus8pymVWWw9SCLAIKfZlgFO4iCZmRIOdVFnDeUYHfNzDEtoZ2Nta3se1A\nO1sPdPD6jmYeWVN/pE00HKC6NIfqkhyqirOZVpxNVVE2VcXZxDLDXqyKiMJd5FQioUCieyZ2zPT2\nnn62NXQcCfytB9p5Y+chHl1bz9GHsQqzI1QVZcVDPxH404rjzzkZ+u8nY0f/ukTOQG40/K69fICe\n/kF2N3ex42AnOw92srOpkx0HO/n99iYeXrX3mLaF2REqCjKZWpBFRUFm/FGYxdSCTCoKsnTdexkV\nhbtIEkXDwURffO675nX1DbCrqYudBzvZ0dTJnuZu6g51sWlf/DILh/v2DyvOyYiHf+E74V8ey2RS\nLMrkWJRYZlgjeuSkFO4i4yQrEmL25DxmT85717yhIUdjRy97mruoO9R95LmupYu1e1p4cv0+BoaO\nHbYcDQeYHMtkUl487A+H/qRY5pH3hVkRHexNUwp3kQkgEDDK8qKU5UWpqXr3/MEhx4G2Hva19rC/\ntYd9rd3x57b4+9d2NHOgreddHwCRYICyWAaluVFKczMoyc2gJCeD0rzDr6OU5mVQlB3Rmbs+o3AX\nSQHBgFGen0l5/smvgjk05DjY2ZsI/54jz/tau2ls72VbQwe/f6uJ1u7+d/2sGRRlRyjOiYd+aW40\nHv65GZTmZlCUE59XmB2hICui8f4pQOEu4hOBgCX20KPMrzh5u57+QQ529NLY3ktD+7HP8UcPbzV0\n0NjRS//gu89gN4P8zDCF2RGKsuOBX5QToSg7QmF2hMKcjCOvi3IiFGbpW4EXFO4iaSYaDlJRkEVF\nQdYp2znnaOnqp6G9l6aOXpo6+2ju7KOps4+mjt4jr7c3dvD6zj4OdfVxsquZxDLDRwI/PytCflaY\n/MwwBdkRYpnhxPvE9Kww+VkRsiNBHTAeBYW7iJyQmVGQHaEgOwK8e/TP8QaHHC1dh8M//kHQ3Hns\nh0JzRx97W7rZWN9KS1f/kUs1n0goYORnhYllhilIfCDEMt/5YMjLDJMbDZEbPfwcIi8aJi8aJica\nSvuuI4W7iCRFMGAU5WRQlJMBZSP7mZ7+Qdq6+2np7qelq59DXX20dvXT0t1HS9fh6fHX9S09bN7X\nTktXH519J/9QOCw7EiQ3GiYv8+gPgPCRD4H487Hzjm6bEwml9EgjhbuIeCYaDhINByk9zcsu9w0M\n0d7TT3vPAO09A7T19NPe009b4v3heW3diTa9/TR39rGrqSvernvgXecVHM8MsiMhcjJCZGcEyckI\nkRMNHZmWEw2RnZGYHwmSEw2TkxE8Mi3+c+/8zHh/k1C4i0jKiYQC73xLOEM9/YPHfhAc+bA4/H6A\njp4BOnsH6Eg8OnsHaOroOvK6o3fghAedTyQzHCQnGg/9G5dU8ukLp59x7SOhcBeRtHT4W0NJ7uju\nu9s7MEhn7yAdPYkPgL7Eh8EJPhg6egfp6B0Yl3v9KtxFREYhIxQkIxSkMDvidSnH0OBTEREfUriL\niPiQwl1ExIcU7iIiPqRwFxHxIYW7iIgPKdxFRHxI4S4i4kPmTnaNzrFesFkjsOsMf7wYOJjEclKB\n1jk9aJ3Tw2jW+SznXMlwjTwL99Ews1rnXI3XdYwnrXN60Dqnh/FYZ3XLiIj4kMJdRMSHUjXc7/a6\nAA9ondOD1jk9jPk6p2Sfu4iInFqq7rmLiMgppFy4m9lVZrbFzLab2Ze8ridZzGyqmT1vZpvNbKOZ\nfS4xvdDMnjWzbYnngsR0M7PvJv4O68zsPG/X4MyYWdDMVpvZ44n308zstcT6/peZRRLTMxLvtyfm\nV3lZ92iYWb6ZPWhmbya29/v8vJ3N7K8S/6Y3mNn9Zhb143Y2s3vMrMHMNhw17bS3q5n9SaL9NjP7\nkzOtJ6XC3cyCwPeBq4E5wHIzm+NtVUkzAPyNc242cD5wW2LdvgQ855ybCTyXeA/xv8HMxONW4N/H\nv+Sk+Byw+aj3/wJ8O7G+h4BbEtNvAQ4556qBbyfaparvAE85584BFhBff19uZzObAvwFUOOcmwcE\ngY/jz+18L3DVcdNOa7uaWSHwVWAJsBj46uEPhNPmnEuZB/A+4Omj3n8Z+LLXdY3Ruj4KXA5sASYn\npk0GtiRe/xBYflT7I+1S5QFUJP7BfwB4HDDiJ3aEjt/ewNPA+xKvQ4l25vU6nME65wE7jq/dr9sZ\nmALsAQoT2+1x4Eq/bmegCthwptsVWA788Kjpx7Q7nUdK7bnzzj+Uw+oS03wl8VV0IfAaUOac2weQ\neC5NNPPD3+IO4G+Bw7ehLwJanHMDifdHr9OR9U3Mb020TzXTgUbgJ4nuqB+bWTY+3c7Oub3AN4Hd\nwD7i220l/t/Oh53udk3a9k61cLcTTPPVcB8zywEeAv7SOdd2qqYnmJYyfwszuwZocM6tPHryCZq6\nEcxLJSHgPODfnXMLgU7e+ap+Iim93okuheuBaUA5kE28S+J4ftvOwznZeiZt/VMt3OuAqUe9rwDq\nPaol6cwsTDzYf+6cezgx+YCZTU7Mnww0JKan+t9iKXCdme0Efkm8a+YOIN/MDt+4/eh1OrK+ifkx\noHk8C06SOqDOOfda4v2DxMPer9v5MmCHc67ROdcPPAxcgP+382Gnu12Ttr1TLdzfAGYmjrRHiB+Y\n+bXHNSWFmRnwH8Bm59y3jpr1a+DwEfM/Id4Xf3j6TYmj7ucDrYe//qUC59yXnXMVzrkq4tvxt865\nG4HngRsSzY5f38N/hxsS7VNuj845tx/YY2ZnJyZdCmzCp9uZeHfM+WaWlfg3fnh9fb2dj3K62/Vp\n4AozK0h867kiMe30eX0A4gwOWPwBsBV4C/jfXteTxPVaRvzr1zpgTeLxB8T7G58DtiWeCxPtjfjI\nobeA9cRHI3i+Hme47hcDjydeTwdeB7YDDwAZienRxPvtifnTva57FOv7HqA2sa0fAQr8vJ2BrwNv\nAhuAnwEZftzOwP3Ejyv0E98Dv+VMtitwc2L9twOfOtN6dIaqiIgPpVq3jIiIjIDCXUTEhxTuIiI+\npHAXEfEhhbuIiA8p3EVEfEjhLiLiQwp3EREf+v85wcgsZ8YkcQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121175c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Save and test your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and save - save all the weights of our graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss is: 1.1355801820755005 and model saved at: /Users/weimin/Desktop/workshop/testing.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "data = {x: data_x, \n",
    "        y: data_y}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    losses = []\n",
    "    for t in range(1000):\n",
    "        loss_val, _  = sess.run([loss, updates], \n",
    "                                feed_dict = data)\n",
    "        losses.append(loss_val)\n",
    "        \n",
    "    saved_path = saver.save(sess, '/Users/weimin/Desktop/workshop/testing.ckpt')\n",
    "print(\"Final loss is: {} and model saved at: {}\".format(losses[-1], saved_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/weimin/Desktop/workshop/testing.ckpt\n",
      "1.13551\n"
     ]
    }
   ],
   "source": [
    "# First, we have to rebuild the graph\n",
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(N, D), name = 'input')\n",
    "y = tf.placeholder(tf.float32, shape=(N, 1), name = 'target')\n",
    "\n",
    "# weights initializer\n",
    "init = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "# hidden layer\n",
    "h = tf.layers.dense(inputs=x, units=H, \n",
    "                    activation=tf.nn.relu, \n",
    "                    kernel_initializer = init, \n",
    "                    name='hidden_layer')\n",
    "\n",
    "# output layer\n",
    "y_pred = tf.layers.dense(inputs=h, units=1, \n",
    "                        kernel_initializer = init, \n",
    "                        name='output_layer')\n",
    "\n",
    "# loss\n",
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "# Second, load the weights from your previously trained model, and test on your data\n",
    "data = {x: data_x, \n",
    "        y: data_y}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore model weights from previously saved model\n",
    "    saver.restore(sess, saved_path)\n",
    "    \n",
    "    final_loss = sess.run(loss, feed_dict = data)\n",
    "print(final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an image classifier using CNN\n",
    "\n",
    "- `tf.nn.conv2d`: https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\n",
    "- `tf.layers.conv2d`: https://www.tensorflow.org/api_docs/python/tf/layers/conv2d\n",
    "- `tf.contrib.layers.convolution2d`: https://www.tensorflow.org/api_guides/python/contrib.layers (not covered)\n",
    "- `tf.nn.max_pool`: https://www.tensorflow.org/api_docs/python/tf/nn/max_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) The hard way - using `tf.nn.conv2d` directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# input image shape is [batch_size, height, width, channels]\n",
    "input_image = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "\n",
    "def conv2d(x, W):\n",
    "  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "  return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def weight_variable(shape, name = None):\n",
    "  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name = name)\n",
    "\n",
    "def bias_variable(shape, name = None):\n",
    "  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name = name)\n",
    "\n",
    "W_conv = weight_variable([5, 5, 3, 64], name = 'W') # [filter_height, filter_width, in_channels, out_channels]\n",
    "b_conv = bias_variable([64], name = 'b')\n",
    "h_conv = tf.nn.relu(conv2d(input_image, W_conv) + b_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 32, 32, 64) dtype=float32>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'W:0' shape=(5, 5, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'b:0' shape=(64,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) The easy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# input image shape is [batch_size, height, width, channels]\n",
    "input_image = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "\n",
    "h_conv = tf.layers.conv2d(\n",
    "  inputs=input_image,\n",
    "  filters=64,\n",
    "  kernel_size=[5, 5],\n",
    "  padding=\"same\",\n",
    "  kernel_initializer=tf.truncated_normal_initializer,\n",
    "  activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d/Relu:0' shape=(?, 32, 32, 64) dtype=float32>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d/bias:0' shape=(64,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool:0' shape=(?, 16, 16, 64) dtype=float32>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool1 = tf.nn.max_pool(h_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "h_pool1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - CNN of a toy image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input - 5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=(5, 4, 4, 3) dtype=float32>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "image_input = tf.constant([\n",
    "            [\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]], \n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]]\n",
    "            ], \n",
    "    \n",
    "            [\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]], \n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]]\n",
    "            ], \n",
    "    \n",
    "            [\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]], \n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]]\n",
    "            ], \n",
    "            [\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]], \n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]]\n",
    "            ], \n",
    "            [\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]], \n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]]\n",
    "            ]\n",
    "        ])\n",
    "image_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv = tf.layers.conv2d(\n",
    "  inputs=image_input,\n",
    "  filters=2,\n",
    "  kernel_size=[1, 1],\n",
    "  padding=\"same\",\n",
    "  kernel_initializer=tf.truncated_normal_initializer,\n",
    "  activation=tf.nn.relu)\n",
    "h_pool = tf.layers.max_pooling2d(inputs=h_conv, pool_size=[2, 2], strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]]\n",
      "\n",
      "  [[   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [   0.          224.10037231]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [   0.          224.10037231]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]]\n",
      "\n",
      "\n",
      " [[[   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]]\n",
      "\n",
      "  [[   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [   0.          224.10037231]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [   0.          224.10037231]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]]\n",
      "\n",
      "\n",
      " [[[   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]]\n",
      "\n",
      "  [[   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [   0.          224.10037231]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [   0.          224.10037231]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]]\n",
      "\n",
      "\n",
      " [[[   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]]\n",
      "\n",
      "  [[   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [   0.          224.10037231]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [   0.          224.10037231]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]]\n",
      "\n",
      "\n",
      " [[[   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]]\n",
      "\n",
      "  [[   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]\n",
      "   [   0.            0.87882495]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [   0.          224.10037231]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [   0.          224.10037231]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]]]\n",
      "Output tensor shape:  (5, 4, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    h_conv_res = sess.run(h_conv)\n",
    "    print(h_conv_res)\n",
    "    print(\"Output tensor shape: \", h_conv_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'max_pooling2d/MaxPool:0' shape=(5, 2, 2, 2) dtype=float32>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Flatten last pooling 1-D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(5, 8) dtype=float32>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_dim = h_pool.get_shape().as_list()[1] * h_pool.get_shape().as_list()[2] * h_pool.get_shape().as_list()[3]\n",
    "h_pool_flat = tf.reshape(h_pool, [-1, flatten_dim])\n",
    "h_pool_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) FC layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('fc1'):\n",
    "    W_fc1 = weight_variable([flatten_dim, 2], name = 'W')\n",
    "    b_fc1 = bias_variable([2], name = 'b')\n",
    "h_fc1 = tf.matmul(h_pool_flat, W_fc1) + b_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(5, 2) dtype=float32>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Batch norm (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(h, is_training):\n",
    "    return tf.contrib.layers.batch_norm(h, \n",
    "                                        center=True, \n",
    "                                        scale=True, \n",
    "                                        is_training=is_training)\n",
    "h_fc1_batchnorm = batch_norm(h_fc1, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=tf.constant([[1,0], \n",
    "                                                                   [1,0], \n",
    "                                                                   [0,1], \n",
    "                                                                   [0,1], \n",
    "                                                                   [1,0]]),\n",
    "                                               logits=h_fc1)\n",
    "loss = tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Training Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d/kernel:0' shape=(1, 1, 3, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'fc1/W:0' shape=(8, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'fc1/b:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm/beta:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm/gamma:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Prediction and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h_fc1\n",
    "y_target = np.array([[1,0], \n",
    "                     [1,0], \n",
    "                     [0,1], \n",
    "                     [0,1], \n",
    "                     [1,0]])\n",
    "probs = tf.nn.softmax(logits)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_target, 1))\n",
    "correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    accuracy = sess.run(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for a random prediction:  0.6\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for a random prediction: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11) The whole script for building graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph(config):\n",
    "    \"\"\"This function builds the graph for a deep net for classifying images.\n",
    "    Args:\n",
    "      config: Model configuration object\n",
    "    Returns:\n",
    "      A tuple (y, keep_prob). y is a tensor of shape (N_examples, 10), with values\n",
    "      equal to the logits of classifying the digit into one of 10 classes (the\n",
    "      digits 0-9). keep_prob is a scalar placeholder for the probability of\n",
    "      dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    x_image = tf.placeholder(tf.float32, [None, config.image_height, config.image_width, config.image_channels])\n",
    "    y = tf.placeholder(tf.float32, [None, int(config.num_classes)])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([config.filter_size, config.filter_size, config.image_channels, config.conv1_num_filters], name = 'W')\n",
    "        b_conv1 = bias_variable([config.conv1_num_filters], name = 'b')\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "    # Pooling layer - downsamples by 2X.\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = weight_variable([config.filter_size, config.filter_size, config.conv1_num_filters, config.conv2_num_filters], name = 'W')\n",
    "        b_conv2 = bias_variable([config.conv2_num_filters], name = 'b')\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "    # Second pooling layer.\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    # Fully connected layer 1 -- after 2 round of downsampling, our 32x32 image\n",
    "    # is down to 8x8x64 feature maps -- maps this to 1024 features.\n",
    "    feature_map_flattened_dim = int((config.image_height/(2*2)) * (config.image_width/(2*2)) * config.conv2_num_filters)\n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = weight_variable([feature_map_flattened_dim, config.fc1_num_features], name = 'W')\n",
    "        b_fc1 = bias_variable([config.fc1_num_features], name = 'b')\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, feature_map_flattened_dim])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "    # features.\n",
    "    with tf.name_scope('dropout'):\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    # Map the 1024 features to 10 classes, one for each digit\n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2 = weight_variable([config.fc1_num_features, config.num_classes], name = 'W')\n",
    "        b_fc2 = bias_variable([config.num_classes], name = 'b')\n",
    "\n",
    "    # Raw predictions - logits\n",
    "    with tf.name_scope('logits'):\n",
    "        logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "    with tf.name_scope('probabilities'):\n",
    "        probs = tf.nn.softmax(logits)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                       logits=logits)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    with tf.name_scope('adam_optimizer'):\n",
    "        train_step = tf.train.AdamOptimizer(config.learning_rate).minimize(loss)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "    saver = tf.train.Saver\n",
    "\n",
    "    # Return the model in dict\n",
    "    return dict(\n",
    "        x_image = x_image, \n",
    "        y = y, \n",
    "        keep_prob = keep_prob, \n",
    "        logits = logits, \n",
    "        probs = probs, \n",
    "        loss = loss, \n",
    "        train_step = train_step, \n",
    "        accuracy = accuracy, \n",
    "        saver = saver, \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12) Train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_for_one_epoch(iterations, train_x, train_y, model, sess):\n",
    "\n",
    "    num_images = len(train_x)\n",
    "    for _ in range(iterations):\n",
    "        # Create a random index.\n",
    "        idx = np.random.choice(num_images,\n",
    "                               size=256,\n",
    "                               replace=False)\n",
    "        batch_x = train_x[idx, :, :, :]\n",
    "        batch_y = train_y[idx, :]\n",
    "\n",
    "        if record_train_loss: \n",
    "            _, temp_loss = sess.run([model['train_step'], model['loss']], feed_dict={model['x_image']: batch_x, \\\n",
    "                                                                                     model['y']: batch_y, \\\n",
    "                                                                                     model['keep_prob']:0.5})\n",
    "            training_loss.append(temp_loss)\n",
    "        else:\n",
    "            sess.run(model['train_step'], feed_dict={model['x_image']: batch_x, \\\n",
    "                                                     model['y']: batch_y, \\\n",
    "                                                     model['keep_prob']:0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13) Model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_prediction(val_x, val_y, model, sess):\n",
    "\n",
    "    val_accur = sess.run(model['accuracy'], feed_dict={model['x_image']: val_x, \\\n",
    "                                                       model['y']: val_y, \\\n",
    "                                                       model['keep_prob']: 1.0})\n",
    "return val_accur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14) Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & val losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/train_losses.png\" />\n",
    "\n",
    "<img src=\"images/val_losses_n_accuracy.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize activations from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "idx = np.random.choice(train_data.shape[0],\n",
    "      size=1,\n",
    "      replace=False)\n",
    "img = train_data[idx[0], :, :, :]\n",
    "## visualize layer-1 kernel weights in grid \n",
    "img = np.expand_dims(img, 0)\n",
    "h_conv1_1 = sess.run(model['h_conv1_1'], feed_dict={model['x_image']:img})\n",
    "h_conv1_1 = h_conv1_1.transpose(3, 1, 2, 0)   # reshape to: (N, H, W, 1)\n",
    "vis_grid = visualize_grid(h_conv1_1, grey = True)\n",
    "plot_weights_in_grid(vis_grid, os.path.join(save_dir, 'vis_activations.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td><img src=\"images/vis_acti_dog.png\" /></td>\n",
    "<td><img src=\"images/vis_acti_frog.png\" /></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the files: \n",
    "****`train.py`:****  To build & train the model, as well as to monitor the training progress and to visualize graphs like above. Upon completion, it will save the trained model into specified location. How to run:                        \n",
    "`python train.py --trainDir /home/ubuntu/workshop/ --savedSessionDir /home/ubuntu/workshop/savedSessions/`\n",
    "\n",
    "**** `build_graph.py`: ****  Build the model graph and return list of nodes to the graph\n",
    "\n",
    "**** `configuration.py`: **** Configuration file for model and training. \n",
    "\n",
    "**** `vis_utils.py`: **** Visualization utility functions\n",
    "\n",
    "**** `data_utils.py`: **** Data utility functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
