{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUS Deep Learning workshop on computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is TensorFlow\n",
    "* A system for executing computational graphs over Tensor objects - n-dimensional arrays analogous to the numpy ndarray.\n",
    "* Native support for performing backpropogation for its Variables. \n",
    "* Used by Google for both research and production. \n",
    "\n",
    "### Why use Tensorflow\n",
    "\n",
    "* Save you a lot of time when buiding large computational graphs - can automatically compute gradients to update weights!\n",
    "* Code can be run on GPU - usually 5x - 20x times faster than CPU for usually image networks. And you don't need to worry about low level cuda-code, things are taken care for you in tf. \n",
    "* A lot of good high level APIs or pre-trained models that you can use directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief example of tensorflow  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph building blocks: \n",
    "1) Placeholder: input nodes to our graph, which serve as entry points where we can feed data into graph - `tf.placeholder`\n",
    "\n",
    "2) Variables: tensors that hold values in the graph, which will be updated during training - `tf.Variable`\n",
    "\n",
    "3) Ops: arithmetic operators, as well as activation, convolution, loss ops and many more - \n",
    "* a = tf.constant([3, 6])\n",
    "* b = tf.constant([2, 2])\n",
    "* tf.add(a, b) # >> [5 8]\n",
    "* tf.add_n([a, b, b]) # >> [7 10]. Equivalent to a + b + b\n",
    "* tf.mul(a, b) # >> [6 12] because mul is element wise\n",
    "* tf.matmul(a, b) # >> ValueError\n",
    "* tf.matmul(tf.reshape(a, shape=[1, 2]), tf.reshape(b, shape=[2, 1])) # >> [[18]]\n",
    "* tf.div(a, b) # >> [1 3]\n",
    "* tf.mod(a, b) # >> [1 0]\n",
    "\n",
    "* tf.nn*, such as tf.nn.conv2d, tf.nn.max_pool, tf.nn.softmax, tf.nn.relu, and so on\n",
    "\n",
    "4) tf.train* subclasses: Optimizer base classes that compute gradients for a loss and apply gradients to variables. Such as tf.train.GradientDescentOptimizer, tf.train.AdadeltaOptimizer, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Build the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1131bfda0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADGCAYAAADc30sqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpwEeiGEiHAS6IUQIsL9P0ttCpDSc3GfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108455eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "img = plt.imread('./images/LM.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "N = 128 # sample size \n",
    "D = 5 # data dimension \n",
    "H = 2 # hidden layer dimension \n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(N, D), name = 'input')\n",
    "y = tf.placeholder(tf.float32, shape=(N, 1), name = 'target')\n",
    "\n",
    "# all weights for model \n",
    "w1 = tf.Variable(tf.random_normal((D, H)), name = 'weights1')\n",
    "b1 = tf.Variable(tf.zeros([2]), name = 'biases1')\n",
    "w2 = tf.Variable(tf.random_normal((H, 1)), name = 'weights2')\n",
    "b2 = tf.Variable(tf.zeros([1]), name = 'biases1')\n",
    "\n",
    "# relu hidden layer\n",
    "h = tf.maximum(tf.matmul(x, w1) + b1, 0)\n",
    "\n",
    "# output layer \n",
    "y_pred = tf.matmul(h, w2) + b2\n",
    "\n",
    "# loss \n",
    "loss = tf.reduce_mean((y_pred - y)**2)\n",
    "\n",
    "# update \n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-3)\n",
    "updates = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'weights1:0' shape=(5, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'biases1:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'weights2:0' shape=(2, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'biases1_1:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x = np.random.randn(N, D)\n",
    "data_y = np.random.randn(N, 1)\n",
    "\n",
    "data = {x: data_x, \n",
    "        y: data_y}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    losses = []\n",
    "    for t in range(1000):\n",
    "        loss_val, _  = sess.run([loss, updates], \n",
    "                                feed_dict = data)\n",
    "        losses.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11d72e8d0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a364be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Can switch to high-level layers too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(N, D), name = 'input')\n",
    "y = tf.placeholder(tf.float32, shape=(N, 1), name = 'target')\n",
    "\n",
    "# weights initializer\n",
    "init = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "# hidden layer\n",
    "h = tf.layers.dense(inputs=x, units=H, \n",
    "                    activation=tf.nn.relu, \n",
    "                    kernel_initializer = init, \n",
    "                    name='hidden_layer')\n",
    "\n",
    "# output layer\n",
    "y_pred = tf.layers.dense(inputs=h, units=1, \n",
    "                        kernel_initializer = init, \n",
    "                        name='output_layer')\n",
    "\n",
    "# loss\n",
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "# updates\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-3)\n",
    "updates = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {x: data_x, \n",
    "        y: data_y}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    losses = []\n",
    "    for t in range(1000):\n",
    "        loss_val, _  = sess.run([loss, updates], \n",
    "                                feed_dict = data)\n",
    "        losses.append(loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x122104390>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n579XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d73fd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Save and test your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and save - save all the weights of our graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss is: 0.9991867542266846 and model saved at: /Users/weimin/Desktop/workshop/testing.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "data = {x: data_x, \n",
    "        y: data_y}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    losses = []\n",
    "    for t in range(1000):\n",
    "        loss_val, _  = sess.run([loss, updates], \n",
    "                                feed_dict = data)\n",
    "        losses.append(loss_val)\n",
    "        \n",
    "    saved_path = saver.save(sess, '/Users/weimin/Desktop/workshop/testing.ckpt')\n",
    "print(\"Final loss is: {} and model saved at: {}\".format(losses[-1], saved_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/weimin/Desktop/workshop/testing.ckpt\n",
      "0.999152\n"
     ]
    }
   ],
   "source": [
    "# First, we have to rebuild the graph\n",
    "# reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(N, D), name = 'input')\n",
    "y = tf.placeholder(tf.float32, shape=(N, 1), name = 'target')\n",
    "\n",
    "# weights initializer\n",
    "init = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "# hidden layer\n",
    "h = tf.layers.dense(inputs=x, units=H, \n",
    "                    activation=tf.nn.relu, \n",
    "                    kernel_initializer = init, \n",
    "                    name='hidden_layer')\n",
    "\n",
    "# output layer\n",
    "y_pred = tf.layers.dense(inputs=h, units=1, \n",
    "                        kernel_initializer = init, \n",
    "                        name='output_layer')\n",
    "\n",
    "# loss\n",
    "loss = tf.losses.mean_squared_error(y_pred, y)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "# Second, load the weights from your previously trained model, and test on your data\n",
    "data = {x: data_x, \n",
    "        y: data_y}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore model weights from previously saved model\n",
    "    saver.restore(sess, saved_path)\n",
    "    \n",
    "    final_loss = sess.run(loss, feed_dict = data)\n",
    "print(final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an image classifier using CNN\n",
    "\n",
    "- `tf.nn.conv2d`: https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\n",
    "- `tf.layers.conv2d`: https://www.tensorflow.org/api_docs/python/tf/layers/conv2d\n",
    "- `tf.contrib.layers.convolution2d`: https://www.tensorflow.org/api_guides/python/contrib.layers (not covered)\n",
    "- `tf.nn.max_pool`: https://www.tensorflow.org/api_docs/python/tf/nn/max_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) The hard way - using `tf.nn.conv2d` directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# input image shape is [batch_size, height, width, channels]\n",
    "input_image = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "\n",
    "def conv2d(x, W):\n",
    "  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "  return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def weight_variable(shape, name = None):\n",
    "  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name = name)\n",
    "\n",
    "def bias_variable(shape, name = None):\n",
    "  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name = name)\n",
    "\n",
    "W_conv = weight_variable([5, 5, 3, 64], name = 'W') # [filter_height, filter_width, in_channels, out_channels]\n",
    "b_conv = bias_variable([64], name = 'b')\n",
    "h_conv = tf.nn.relu(conv2d(input_image, W_conv) + b_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 32, 32, 64) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'W:0' shape=(5, 5, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'b:0' shape=(64,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) The easy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# input image shape is [batch_size, height, width, channels]\n",
    "input_image = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "\n",
    "h_conv = tf.layers.conv2d(\n",
    "  inputs=input_image,\n",
    "  filters=64,\n",
    "  kernel_size=[5, 5],\n",
    "  padding=\"same\",\n",
    "  kernel_initializer=tf.truncated_normal_initializer,\n",
    "  activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d/Relu:0' shape=(?, 32, 32, 64) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d/kernel:0' shape=(5, 5, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d/bias:0' shape=(64,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool:0' shape=(?, 16, 16, 64) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool1 = tf.nn.max_pool(h_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "h_pool1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - CNN of a toy image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input - 5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=(5, 4, 4, 3) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "image_input = tf.constant([\n",
    "            [\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]], \n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]]\n",
    "            ], \n",
    "    \n",
    "            [\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]], \n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]]\n",
    "            ], \n",
    "    \n",
    "            [\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]], \n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]]\n",
    "            ], \n",
    "            [\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]], \n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]]\n",
    "            ], \n",
    "            [\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]],\n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]], \n",
    "                [[254., 0., 0.], [255., 255., 255.], [0., 0., 0.], [0., 0., 0.]]\n",
    "            ]\n",
    "        ])\n",
    "image_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv = tf.layers.conv2d(\n",
    "  inputs=image_input,\n",
    "  filters=2,\n",
    "  kernel_size=[1, 1],\n",
    "  padding=\"same\",\n",
    "  kernel_initializer=tf.truncated_normal_initializer,\n",
    "  activation=tf.nn.relu)\n",
    "h_pool = tf.layers.max_pooling2d(inputs=h_conv, pool_size=[2, 2], strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]]\n",
      "\n",
      "  [[   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [ 271.65869141    0.        ]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [ 271.65869141    0.        ]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]]\n",
      "\n",
      "\n",
      " [[[   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]]\n",
      "\n",
      "  [[   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [ 271.65869141    0.        ]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [ 271.65869141    0.        ]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]]\n",
      "\n",
      "\n",
      " [[[   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]]\n",
      "\n",
      "  [[   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [ 271.65869141    0.        ]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [ 271.65869141    0.        ]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]]\n",
      "\n",
      "\n",
      " [[[   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]]\n",
      "\n",
      "  [[   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [ 271.65869141    0.        ]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [ 271.65869141    0.        ]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]]\n",
      "\n",
      "\n",
      " [[[   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]]\n",
      "\n",
      "  [[   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]\n",
      "   [   1.06532812    0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [ 271.65869141    0.        ]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]\n",
      "\n",
      "  [[   0.            0.        ]\n",
      "   [ 271.65869141    0.        ]\n",
      "   [   0.            0.        ]\n",
      "   [   0.            0.        ]]]]\n",
      "Output tensor shape:  (5, 4, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    h_conv_res = sess.run(h_conv)\n",
    "    print(h_conv_res)\n",
    "    print(\"Output tensor shape: \", h_conv_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'max_pooling2d/MaxPool:0' shape=(5, 2, 2, 2) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Flatten last pooling 1-D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(5, 8) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_dim = h_pool.get_shape().as_list()[1] * h_pool.get_shape().as_list()[2] * h_pool.get_shape().as_list()[3]\n",
    "h_pool_flat = tf.reshape(h_pool, [-1, flatten_dim])\n",
    "h_pool_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) FC layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('fc1'):\n",
    "    W_fc1 = weight_variable([flatten_dim, 2], name = 'W')\n",
    "    b_fc1 = bias_variable([2], name = 'b')\n",
    "h_fc1 = tf.matmul(h_pool_flat, W_fc1) + b_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(5, 2) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Batch norm (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(h, is_training):\n",
    "    return tf.contrib.layers.batch_norm(h, \n",
    "                                        center=True, \n",
    "                                        scale=True, \n",
    "                                        is_training=is_training)\n",
    "h_fc1_batchnorm = batch_norm(h_fc1, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=tf.constant([[1,0], \n",
    "                                                                   [1,0], \n",
    "                                                                   [0,1], \n",
    "                                                                   [0,1], \n",
    "                                                                   [1,0]]),\n",
    "                                               logits=h_fc1)\n",
    "loss = tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Training Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d/kernel:0' shape=(1, 1, 3, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d/bias:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'fc1/W:0' shape=(8, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'fc1/b:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm/beta:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'BatchNorm/gamma:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Prediction and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = h_fc1\n",
    "y_target = np.array([[1,0], \n",
    "                     [1,0], \n",
    "                     [0,1], \n",
    "                     [0,1], \n",
    "                     [1,0]])\n",
    "probs = tf.nn.softmax(logits)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_target, 1))\n",
    "correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    accuracy = sess.run(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for a random prediction:  0.6\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for a random prediction: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The whole script for building graph - to understand ```train.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Build the CNN graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph(config):\n",
    "    \"\"\"This function builds the graph for a deep net for classifying images.\n",
    "    Args:\n",
    "      config: Model configuration object\n",
    "    Returns:\n",
    "      A tuple (y, keep_prob). y is a tensor of shape (N_examples, 10), with values\n",
    "      equal to the logits of classifying the image into one of 10 classes (the\n",
    "      digits 0-9). keep_prob is a scalar placeholder for the probability of\n",
    "      dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    x_image = tf.placeholder(tf.float32, [None, config.image_height, config.image_width, config.image_channels])\n",
    "    y = tf.placeholder(tf.float32, [None, int(config.num_classes)])\n",
    "    is_training = tf.placeholder(tf.bool, [])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    # First convolutional module [conv-conv-pool] -- maps one grayscale image to 32 feature maps.\n",
    "    with tf.name_scope('conv1_1'):\n",
    "        W_conv1_1 = weight_variable([config.filter_size, config.filter_size, config.image_channels, config.conv1_num_filters], name = 'W')\n",
    "        b_conv1_1 = bias_variable([config.conv1_num_filters], name = 'b')\n",
    "        c_conv1_1 = conv2d(x_image, W_conv1_1) + b_conv1_1\n",
    "        #c_conv1_1 = batch_norm1(c_conv1_1, is_training)\n",
    "        h_conv1_1 = tf.nn.relu(c_conv1_1)\n",
    "\n",
    "    with tf.name_scope('conv1_2'):\n",
    "        W_conv1_2 = weight_variable([config.filter_size, config.filter_size, config.conv1_num_filters, config.conv1_num_filters], name = 'W')\n",
    "        b_conv1_2 = bias_variable([config.conv1_num_filters], name = 'b')\n",
    "        c_conv1_2 = conv2d(h_conv1_1, W_conv1_2) + b_conv1_2\n",
    "        #c_conv1_2 = batch_norm1(c_conv1_2, is_training)\n",
    "        h_conv1_2 = tf.nn.relu(c_conv1_2)\n",
    "\n",
    "    # Pooling layer - downsamples by 2X.\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1_2)\n",
    "\n",
    "    # Second convolutional module [conv-conv-pool] -- maps 32 feature maps to 64.\n",
    "    with tf.name_scope('conv2_1'):\n",
    "        W_conv2_1 = weight_variable([config.filter_size, config.filter_size, config.conv1_num_filters, config.conv2_num_filters], name = 'W')\n",
    "        b_conv2_1 = bias_variable([config.conv2_num_filters], name = 'b')\n",
    "        c_conv2_1 = conv2d(h_pool1, W_conv2_1) + b_conv2_1\n",
    "        #c_conv2_1 = batch_norm1(c_conv2_1, is_training)\n",
    "        h_conv2_1 = tf.nn.relu(c_conv2_1)\n",
    "\n",
    "    with tf.name_scope('conv2_2'):\n",
    "        W_conv2_2 = weight_variable([config.filter_size, config.filter_size, config.conv2_num_filters, config.conv2_num_filters], name = 'W')\n",
    "        b_conv2_2 = bias_variable([config.conv2_num_filters], name = 'b')\n",
    "        c_conv2_2 = conv2d(h_conv2_1, W_conv2_2) + b_conv2_2\n",
    "        #c_conv2_2 = batch_norm1(c_conv2_2, is_training)\n",
    "        h_conv2_2 = tf.nn.relu(c_conv2_2)\n",
    "        \n",
    "    # Second pooling layer.\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2_2)\n",
    "\n",
    "    # Fully connected layer 1 -- after 2 round of downsampling, our 32x32 image\n",
    "    # is down to 4x4x64 feature maps -- maps this to 1024 features.\n",
    "    #feature_map_flattened_dim = int((config.image_height/(2**2)) * (config.image_width/(2**2)) * config.conv2_num_filters)\n",
    "    feature_map_flattened_dim = int(np.prod(h_pool2.get_shape()[1:]))\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, feature_map_flattened_dim])\n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = weight_variable([feature_map_flattened_dim, config.fc1_num_features], name = 'W')\n",
    "        b_fc1 = bias_variable([config.fc1_num_features], name = 'b')\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    with tf.name_scope('dropout1'):\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    \"\"\"with tf.name_scope('fc2'):\n",
    "        W_fc2 = weight_variable([config.fc1_num_features, config.fc2_num_features], name = 'W')\n",
    "        b_fc2 = bias_variable([config.fc2_num_features], name = 'b')\n",
    "    h_fc2 = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    #h_fc2 = batch_norm1(h_fc2, is_training)\n",
    "    h_fc2 = tf.nn.relu(h_fc2)\n",
    "    with tf.name_scope('dropout2'):\n",
    "        h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\"\"\"\n",
    "\n",
    "    # Map the 1024 features to 10 classes, one for each digit\n",
    "    with tf.name_scope('fc3'):\n",
    "        W_fc3 = weight_variable([config.fc1_num_features, config.num_classes], name = 'W')\n",
    "        b_fc3 = bias_variable([config.num_classes], name = 'b')\n",
    "    \n",
    "    # Raw predictions - logits\n",
    "    with tf.name_scope('logits'):\n",
    "        logits = tf.matmul(h_fc1_drop, W_fc3) + b_fc3\n",
    "\n",
    "    with tf.name_scope('probabilities'):\n",
    "        probs = tf.nn.softmax(logits)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                       logits=logits)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        with tf.name_scope('adam_optimizer'):\n",
    "            train_step = tf.train.AdamOptimizer(config.learning_rate).minimize(loss)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "    saver = tf.train.Saver\n",
    "\n",
    "    # Return the model in dict\n",
    "    return dict(\n",
    "        x_image = x_image, \n",
    "        y = y, \n",
    "        is_training = is_training, \n",
    "        keep_prob = keep_prob, \n",
    "        h_conv1_1 = h_conv1_1,\n",
    "        logits = logits, \n",
    "        probs = probs, \n",
    "        loss = loss, \n",
    "        train_step = train_step, \n",
    "        accuracy = accuracy, \n",
    "        saver = saver, \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_for_one_epoch(iterations, train_x, train_y, model, sess, config, record_train_loss = False):\n",
    "\n",
    "    num_images = len(train_x)\n",
    "    for i in range(iterations):\n",
    "        # Create a random index.\n",
    "        idx = np.random.choice(num_images,\n",
    "                               size=config.batch_size,\n",
    "                               replace=False)\n",
    "        batch_x = train_x[idx, :, :, :]\n",
    "        batch_y = train_y[idx, :]\n",
    "\n",
    "        \n",
    "        _, temp_loss = sess.run([model['train_step'], model['loss']], feed_dict={model['x_image']: batch_x, \\\n",
    "                                                                                 model['y']: batch_y, \\\n",
    "                                                                                 model['is_training']: True, \\\n",
    "                                                                                 model['keep_prob']:config.keep_rate})\n",
    "        if record_train_loss: \n",
    "            training_loss.append(temp_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(val_x, val_y, model, sess, list_to_pred):\n",
    "\n",
    "    predictions = sess.run([model[p] for p in list_to_pred], feed_dict={model['x_image']: val_x, \\\n",
    "                                                                        model['y']: val_y, \\\n",
    "                                                                        model['is_training']: False, \\\n",
    "                                                                        model['keep_prob']: 1.0})\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Visualization for loss accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train & val losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/train_losses.png\" />\n",
    "\n",
    "<img src=\"images/val_losses_n_accuracy.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Visualize activations from images - cell below for explanation only, please don't run it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(train_data.shape[0],\n",
    "      size=1,\n",
    "      replace=False)\n",
    "img = train_data[idx[0], :, :, :]\n",
    "## visualize layer-1 kernel weights in grid \n",
    "img = np.expand_dims(img, 0)\n",
    "h_conv1_1 = sess.run(model['h_conv1_1'], feed_dict={model['x_image']:img})\n",
    "h_conv1_1 = h_conv1_1.transpose(3, 1, 2, 0)   # reshape to: (N, H, W, 1)\n",
    "vis_grid = visualize_grid(h_conv1_1, grey = True)\n",
    "plot_weights_in_grid(vis_grid, os.path.join(save_dir, 'vis_activations.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td><img src=\"images/vis_acti_dog.png\" /></td>\n",
    "<td><img src=\"images/vis_acti_frog.png\" /></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the files: \n",
    "****`train.py`:****  To build & train the model, as well as to monitor the training progress and to visualize graphs like above. Upon completion, it will save the trained model into specified location. How to run:                        \n",
    "`python train.py --trainDir /home/ubuntu/workshop/ --savedSessionDir /home/ubuntu/workshop/savedSessions/`\n",
    "\n",
    "**** `build_graph.py`: ****  Build the model graph and return list of nodes to the graph\n",
    "\n",
    "**** `configuration.py`: **** Configuration file for model and training. \n",
    "\n",
    "**** `vis_utils.py`: **** Visualization utility functions\n",
    "\n",
    "**** `data_utils.py`: **** Data utility functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
